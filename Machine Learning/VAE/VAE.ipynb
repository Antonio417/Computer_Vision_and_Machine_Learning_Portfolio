{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75ae5f81",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6e6fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "import keras\n",
    "from keras import backend as k\n",
    "k.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2d56c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameter\n",
    "image_shape = (28,28,1)\n",
    "batch_size = 64\n",
    "latent_dim = 10\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25dec047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MNIST dataset\n",
    "(x_train, y_train), (x_test,y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55141fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datatype and reshape data\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape((x_train.shape[0],) + image_shape)\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape((x_test.shape[0],) + image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c6dc77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will give us 10 labelled handwritten images from 0-9 \n",
    "def get_10_image(x_train,y_train):\n",
    "    selected_x,selected_y = [],[]\n",
    "    for i in range(10):\n",
    "        number_index = np.where(y_train == i)[0]\n",
    "        random_index = np.random.choice(len(number_index),1,replace=False)\n",
    "        select_index = number_index[random_index]\n",
    "        selected_x.append(x_train[select_index[0]])\n",
    "        selected_y.append(y_train[select_index][0])\n",
    "    return np.array(selected_x,dtype=\"float32\").reshape((len(selected_x),)+image_shape),np.array(selected_y,dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1088892",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_x,selected_y =  get_10_image(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf787da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 28, 28, 1)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(selected_x.shape) # 10 images of 28 x 28\n",
    "print(selected_y.shape) # 10 labels for each corresponding image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d37cc9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(selected_x,selected_y,title=None,save=None):\n",
    "    ncols = selected_x.shape[0]\n",
    "    fig,ax  = plt.subplots(nrows=1, ncols=ncols,figsize=(20,3))\n",
    "    for x,y,ax_i in zip(selected_x,selected_y,ax):\n",
    "        ax_i.imshow(x.reshape((28,28)))\n",
    "        ax_i.axis(\"off\")\n",
    "        ax_i.set_title(int(y))\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "    if save:\n",
    "        fig.savefig(str(save)+\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce09237d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(selected_x,selected_y,title=\"initial image\",save=\"initial image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c4245",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b82389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 10:01:19.448894: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-12 10:01:19.449340: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# input shape = (None,28,28,1)\n",
    "encoder_input = keras.Input(shape=image_shape)\n",
    "\n",
    "# input shape = (None,28,28,1)\n",
    "# output shape = (None,28,28,32)\n",
    "conv_1 = keras.layers.Conv2D(filters=32,\n",
    "                             kernel_size=3,\n",
    "                             padding=\"same\",\n",
    "                             activation=\"relu\",\n",
    "                            )(encoder_input)\n",
    "\n",
    "# input shape = (None,28,28,32)\n",
    "# output shape = (None,28,28,64)\n",
    "conv_2 = keras.layers.Conv2D(filters=64,\n",
    "                             kernel_size=3,\n",
    "                             padding=\"same\",\n",
    "                             activation=\"relu\",\n",
    "                            )(conv_1)\n",
    "\n",
    "# input shape = (None,28,28,64)\n",
    "# output shape = (None,28,28,64)\n",
    "conv_3 = keras.layers.Conv2D(filters=64,\n",
    "                             kernel_size=3,\n",
    "                             padding=\"same\",\n",
    "                             activation=\"relu\",\n",
    "                            )(conv_2)\n",
    "\n",
    "# input shape = (None,28,28,64)\n",
    "# output shape = (None,50176)\n",
    "flatten = keras.layers.Flatten()(conv_3)\n",
    "\n",
    "# input shape = (None,50176)\n",
    "# output shape = (None,128)\n",
    "encoder_output = keras.layers.Dense(128,activation=\"relu\")(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b866973",
   "metadata": {},
   "source": [
    "## Latent Space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08bd1c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape = (None,128)\n",
    "# output shape = (None,latent_dim)\n",
    "z_mu = keras.layers.Dense(latent_dim)(encoder_output)\n",
    "\n",
    "# input shape = (None,128)\n",
    "# output shape = (None,latent_dim)\n",
    "z_log_sigma = keras.layers.Dense(latent_dim)(encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "185967ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = k.random_normal(shape=(k.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "    return z_mean + k.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35790214",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = keras.layers.Lambda(sampling,output_shape=(latent_dim,))([z_mu, z_log_sigma])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888de8d9",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0f81ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape = (None,latent_dim)\n",
    "# output shape = (None,128)\n",
    "dense_2 = keras.layers.Dense(128,activation=\"relu\")\n",
    "\n",
    "# input shape = (None,128)\n",
    "# output shape = (None,50176)\n",
    "dense_3 = keras.layers.Dense(np.prod(k.int_shape(conv_3)[1:]),activation=\"relu\")\n",
    "\n",
    "# Reshape layer\n",
    "# input shape = (None,128)\n",
    "# output shape = (None,28,28,64)\n",
    "reshape = keras.layers.Reshape(k.int_shape(conv_3)[1:])\n",
    "\n",
    "# Deconvolutional layer 1\n",
    "# input shape = (None,28,28,64)\n",
    "# output shape = (None,28,28,64)\n",
    "conv_4 = keras.layers.Conv2DTranspose(filters=64,\n",
    "                                      kernel_size=3,\n",
    "                                      padding=\"same\",\n",
    "                                      activation=\"relu\"\n",
    "                                     )\n",
    "\n",
    "# Deconvolutional layer 2\n",
    "# input shape = (None,28,28,64)\n",
    "# output shape = (None,28,28,64)\n",
    "conv_5 = keras.layers.Conv2DTranspose(filters=64,\n",
    "                                      kernel_size=3,\n",
    "                                      padding=\"same\",\n",
    "                                      activation=\"relu\"\n",
    "                                     )\n",
    "\n",
    "# Deconvolutional layer 3\n",
    "# input shape = (None,28,28,64)\n",
    "# output shape = (None,28,28,32)\n",
    "conv_6 = keras.layers.Conv2DTranspose(filters=32,\n",
    "                                      kernel_size=3,\n",
    "                                      padding=\"same\",\n",
    "                                      activation=\"relu\"\n",
    "                                     )\n",
    "\n",
    "# convolutional layer 4\n",
    "# input shape = (None,28,28,32)\n",
    "# output shape = (None,28,28,1)\n",
    "decoder_output = keras.layers.Conv2D(filters=1,\n",
    "                                     kernel_size=3,\n",
    "                                     padding=\"same\",\n",
    "                                     activation=\"sigmoid\"\n",
    "                                    )\n",
    "_dense_2 = dense_2(z)\n",
    "_dense_3 = dense_3(_dense_2)\n",
    "_reshape = reshape(_dense_3)\n",
    "_conv_4 = conv_4(_reshape)\n",
    "_conv_5 = conv_5(_conv_4)\n",
    "_conv_6 = conv_6(_conv_5)\n",
    "_decoder_output = decoder_output(_conv_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0647fa82",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "031869ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x, z_decoded):\n",
    "        x = k.flatten(x)\n",
    "        z_decoded = k.flatten(z_decoded)\n",
    "        # Reconstruction loss\n",
    "        Reconstruction_loss = 786*keras.metrics.binary_crossentropy(x, z_decoded)\n",
    "        # KL divergence\n",
    "        kl_loss = -0.5 * k.mean(1 + z_log_sigma - k.square(z_mu) - k.exp(z_log_sigma), axis=-1)\n",
    "        return Reconstruction_loss + kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386a2a50",
   "metadata": {},
   "source": [
    "## VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "226e3de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 64)   18496       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 64)   36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 50176)        0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          6422656     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           1290        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           1290        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 10)           0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          1408        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50176)        6472704     dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 28, 28, 64)   0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 64)   36928       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 64)   36928       conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 28, 28, 32)   18464       conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 28, 28, 1)    289         conv2d_transpose_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 13,047,701\n",
      "Trainable params: 13,047,701\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "variational_encoder = keras.Model(encoder_input,_decoder_output)\n",
    "variational_encoder.compile(optimizer='rmsprop',loss=vae_loss)\n",
    "variational_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78af0e04",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed1ad76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 1311s 22ms/step - loss: 115.5480 - val_loss: 94.1972\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1373s 23ms/step - loss: 87.0171 - val_loss: 83.3149\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1430s 24ms/step - loss: 82.1619 - val_loss: 81.2650\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1287s 21ms/step - loss: 79.4019 - val_loss: 79.1056\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1285s 21ms/step - loss: 77.5361 - val_loss: 77.8817\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1283s 21ms/step - loss: 76.1647 - val_loss: 77.9974\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1293s 22ms/step - loss: 75.0768 - val_loss: 76.4712\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1287s 21ms/step - loss: 74.1608 - val_loss: 76.2113\n",
      "Epoch 9/10\n",
      "15104/60000 [======>.......................] - ETA: 15:05 - loss: 73.1741"
     ]
    }
   ],
   "source": [
    "variational_encoder.fit(x=x_train,y=x_train,\n",
    "                        shuffle=True,\n",
    "                        epochs=epoch,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(x_test,x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac894b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained weights\n",
    "variational_encoder.save_weights('vae_E10.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
