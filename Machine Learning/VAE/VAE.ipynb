{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75ae5f81",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6e6fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "import keras\n",
    "from keras import backend as k\n",
    "k.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2d56c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameter\n",
    "image_shape = (28,28,1)\n",
    "batch_size = 64\n",
    "latent_dim = 10\n",
    "epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25dec047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MNIST dataset\n",
    "(x_train, y_train), (x_test,y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55141fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datatype and reshape data\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape((x_train.shape[0],) + image_shape)\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape((x_test.shape[0],) + image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c6dc77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will give us 10 labelled handwritten images from 0-9 \n",
    "def get_10_image(x_train,y_train):\n",
    "    selected_x,selected_y = [],[]\n",
    "    for i in range(10):\n",
    "        number_index = np.where(y_train == i)[0]\n",
    "        random_index = np.random.choice(len(number_index),1,replace=False)\n",
    "        select_index = number_index[random_index]\n",
    "        selected_x.append(x_train[select_index[0]])\n",
    "        selected_y.append(y_train[select_index][0])\n",
    "    return np.array(selected_x,dtype=\"float32\").reshape((len(selected_x),)+image_shape),np.array(selected_y,dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1088892",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_x,selected_y =  get_10_image(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf787da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 28, 28, 1)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(selected_x.shape) # 10 images of 28 x 28\n",
    "print(selected_y.shape) # 10 labels for each corresponding image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d37cc9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(selected_x,selected_y,title=None,save=None):\n",
    "    ncols = selected_x.shape[0]\n",
    "    fig,ax  = plt.subplots(nrows=1, ncols=ncols,figsize=(20,3))\n",
    "    for x,y,ax_i in zip(selected_x,selected_y,ax):\n",
    "        ax_i.imshow(x.reshape((28,28)))\n",
    "        ax_i.axis(\"off\")\n",
    "        ax_i.set_title(int(y))\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "    if save:\n",
    "        fig.savefig(str(save)+\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce09237d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(selected_x,selected_y,title=\"initial image\",save=\"initial image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c4245",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b82389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 18:44:03.784280: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-11 18:44:03.784655: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# input shape = (None,28,28,1)\n",
    "encoder_input = keras.Input(shape=image_shape)\n",
    "\n",
    "# input shape = (None,28,28,1)\n",
    "# output shape = (None,28,28,32)\n",
    "conv_1 = keras.layers.Conv2D(filters=32,\n",
    "                             kernel_size=3,\n",
    "                             padding=\"same\",\n",
    "                             activation=\"relu\",\n",
    "                            )(encoder_input)\n",
    "\n",
    "# input shape = (None,28,28,32)\n",
    "# output shape = (None,28,28,64)\n",
    "conv_2 = keras.layers.Conv2D(filters=64,\n",
    "                             kernel_size=3,\n",
    "                             padding=\"same\",\n",
    "                             activation=\"relu\",\n",
    "                            )(conv_1)\n",
    "\n",
    "# input shape = (None,28,28,64)\n",
    "# output shape = (None,28,28,64)\n",
    "conv_3 = keras.layers.Conv2D(filters=64,\n",
    "                             kernel_size=3,\n",
    "                             padding=\"same\",\n",
    "                             activation=\"relu\",\n",
    "                            )(conv_2)\n",
    "\n",
    "# input shape = (None,28,28,64)\n",
    "# output shape = (None,50176)\n",
    "flatten = keras.layers.Flatten()(conv_3)\n",
    "\n",
    "# input shape = (None,50176)\n",
    "# output shape = (None,128)\n",
    "encoder_output = keras.layers.Dense(128,activation=\"relu\")(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b866973",
   "metadata": {},
   "source": [
    "## Latent Space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08bd1c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape = (None,128)\n",
    "# output shape = (None,latent_dim)\n",
    "z_mu = keras.layers.Dense(latent_dim)(encoder_output)\n",
    "\n",
    "# input shape = (None,128)\n",
    "# output shape = (None,latent_dim)\n",
    "z_log_sigma = keras.layers.Dense(latent_dim)(encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "185967ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = k.random_normal(shape=(k.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "    return z_mean + k.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35790214",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = keras.layers.Lambda(sampling,output_shape=(latent_dim,))([z_mu, z_log_sigma])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888de8d9",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0f81ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape = (None,latent_dim)\n",
    "# output shape = (None,128)\n",
    "dense_2 = keras.layers.Dense(128,activation=\"relu\")\n",
    "\n",
    "# input shape = (None,128)\n",
    "# output shape = (None,50176)\n",
    "dense_3 = keras.layers.Dense(np.prod(k.int_shape(conv_3)[1:]),activation=\"relu\")\n",
    "\n",
    "# Reshape layer\n",
    "# input shape = (None,128)\n",
    "# output shape = (None,28,28,64)\n",
    "reshape = keras.layers.Reshape(k.int_shape(conv_3)[1:])\n",
    "\n",
    "# Deconvolutional layer 1\n",
    "# input shape = (None,28,28,64)\n",
    "# output shape = (None,28,28,64)\n",
    "conv_4 = keras.layers.Conv2DTranspose(filters=64,\n",
    "                                      kernel_size=3,\n",
    "                                      padding=\"same\",\n",
    "                                      activation=\"relu\"\n",
    "                                     )\n",
    "\n",
    "# Deconvolutional layer 2\n",
    "# input shape = (None,28,28,64)\n",
    "# output shape = (None,28,28,64)\n",
    "conv_5 = keras.layers.Conv2DTranspose(filters=64,\n",
    "                                      kernel_size=3,\n",
    "                                      padding=\"same\",\n",
    "                                      activation=\"relu\"\n",
    "                                     )\n",
    "\n",
    "# Deconvolutional layer 3\n",
    "# input shape = (None,28,28,64)\n",
    "# output shape = (None,28,28,32)\n",
    "conv_6 = keras.layers.Conv2DTranspose(filters=32,\n",
    "                                      kernel_size=3,\n",
    "                                      padding=\"same\",\n",
    "                                      activation=\"relu\"\n",
    "                                     )\n",
    "\n",
    "# convolutional layer 4\n",
    "# input shape = (None,28,28,32)\n",
    "# output shape = (None,28,28,1)\n",
    "decoder_output = keras.layers.Conv2D(filters=1,\n",
    "                                     kernel_size=3,\n",
    "                                     padding=\"same\",\n",
    "                                     activation=\"sigmoid\"\n",
    "                                    )\n",
    "_dense_2 = dense_2(z)\n",
    "_dense_3 = dense_3(_dense_2)\n",
    "_reshape = reshape(_dense_3)\n",
    "_conv_4 = conv_4(_reshape)\n",
    "_conv_5 = conv_5(_conv_4)\n",
    "_conv_6 = conv_6(_conv_5)\n",
    "_decoder_output = decoder_output(_conv_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0647fa82",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "031869ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x, z_decoded):\n",
    "        x = k.flatten(x)\n",
    "        z_decoded = k.flatten(z_decoded)\n",
    "        # Reconstruction loss\n",
    "        Reconstruction_loss = 786*keras.metrics.binary_crossentropy(x, z_decoded)\n",
    "        # KL divergence\n",
    "        kl_loss = -0.5 * k.mean(1 + z_log_sigma - k.square(z_mu) - k.exp(z_log_sigma), axis=-1)\n",
    "        return Reconstruction_loss + kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386a2a50",
   "metadata": {},
   "source": [
    "## VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "226e3de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 64)   18496       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 64)   36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 50176)        0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          6422656     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           1290        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           1290        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 10)           0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          1408        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50176)        6472704     dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 28, 28, 64)   0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 64)   36928       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 64)   36928       conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 28, 28, 32)   18464       conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 28, 28, 1)    289         conv2d_transpose_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 13,047,701\n",
      "Trainable params: 13,047,701\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "variational_encoder = keras.Model(encoder_input,_decoder_output)\n",
    "variational_encoder.compile(optimizer='rmsprop',loss=vae_loss)\n",
    "variational_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe9515a",
   "metadata": {},
   "source": [
    "## Plotting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41e01831",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "`pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1861\u001b[0m                 \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m                 stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot': 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1867\u001b[0m                     prog=prog)\n\u001b[0;32m-> 1868\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1869\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/db/96q4k_9n5s9fk3my0k61nlhr0000gn/T/ipykernel_46163/3696155950.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariational_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"variational_encoder_L{}_E_{}.png\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \"\"\"\n\u001b[1;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[0;32m--> 240\u001b[0;31m                        expand_nested, dpi)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dashed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         raise OSError(\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;34m'`pydot` failed to call GraphViz.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;34m'Please install GraphViz (https://www.graphviz.org/) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             'and ensure that its executables are in the $PATH.')\n",
      "\u001b[0;31mOSError\u001b[0m: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH."
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(variational_encoder,to_file=\"variational_encoder_L{}_E_{}.png\".format(latent_dim,epoch),show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da06d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
