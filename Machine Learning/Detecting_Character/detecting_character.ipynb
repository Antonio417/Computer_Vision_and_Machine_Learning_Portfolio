{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "34522254",
      "metadata": {
        "id": "34522254"
      },
      "source": [
        "## Simpson Character Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0a4b28a",
      "metadata": {
        "id": "e0a4b28a"
      },
      "source": [
        "The dataset are accessible through\n",
        "https://www.kaggle.com/datasets/alexattia/the-simpsons-characters-dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f90a642b",
      "metadata": {
        "id": "f90a642b"
      },
      "source": [
        "Aim: Build a model that could accurately identify character's name inside an image. Challenges arise in this project mainly comes from the randomness of the dataset where for each character, they are presented in a variety of situations with different backgrounds, different angles, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2e1dc08a",
      "metadata": {
        "id": "2e1dc08a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np            \n",
        "import matplotlib.pyplot as plt         \n",
        "import os \n",
        "import copy \n",
        "import itertools \n",
        "from tensorflow import keras \n",
        "from keras.utils.np_utils import to_categorical \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator             \n",
        "from PIL import Image             \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect Drive to Colab\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  has_colab=True\n",
        "except ImportError:\n",
        "  has_colab=False\n",
        "\n",
        "if has_colab:\n",
        "  import os\n",
        "  default_path='/content/drive/MyDrive/Detecting_Character'\n",
        "  os.chdir(default_path)\n",
        "else:\n",
        "  os.chdir('/..')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vV08jJZuv1h",
        "outputId": "cc8681cf-2612-4fe1-ca09-4f0914d6ca89"
      },
      "id": "5vV08jJZuv1h",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73ae0aa5",
      "metadata": {
        "id": "73ae0aa5"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/Detecting_Character/detecting_character_dataset/simpsons_dataset/'\n",
        "test_path = '/content/drive/MyDrive/Detecting_Character/detecting_character_dataset/kaggle_simpson_testset/'"
      ],
      "metadata": {
        "id": "H9CKoacbvd2A"
      },
      "id": "H9CKoacbvd2A",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(train_path)\n",
        "classes = len(os.listdir(train_path)) # How many classes are there?\n",
        "characters = sorted(os.listdir(train_path)) # List of characters\n",
        "print(classes) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5QtPle4xULN",
        "outputId": "3b6b520c-b08e-4e05-f119-d987a1880ab4"
      },
      "id": "N5QtPle4xULN",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Training Set"
      ],
      "metadata": {
        "id": "l2DziQJ7xrP7"
      },
      "id": "l2DziQJ7xrP7"
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (112,112)\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for i in characters:     # Iterating through all directories in the training set\n",
        "    path = train_path + '/' + i\n",
        "    images = sorted(os.listdir(path))\n",
        "\n",
        "    for file in images:    # Iterating through all the images in each directory\n",
        "        try:\n",
        "            image = Image.open(path + '/' + file)\n",
        "            image = image.resize(img_size)   \n",
        "            image = np.array(image)\n",
        "            data.append(image)\n",
        "            labels.append(i)        # Every directory has the name of its label\n",
        "        except:\n",
        "            print(f'Error loading image, character: {i}, file: {file}')\n",
        "\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYc6A_aOy8Ff",
        "outputId": "9e5b6c06-0d4f-4727-b54d-9f6d7e22738b"
      },
      "id": "xYc6A_aOy8Ff",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image, character: simpsons_dataset, file: abraham_grampa_simpson\n",
            "Error loading image, character: simpsons_dataset, file: agnes_skinner\n",
            "Error loading image, character: simpsons_dataset, file: apu_nahasapeemapetilon\n",
            "Error loading image, character: simpsons_dataset, file: barney_gumble\n",
            "Error loading image, character: simpsons_dataset, file: bart_simpson\n",
            "Error loading image, character: simpsons_dataset, file: carl_carlson\n",
            "Error loading image, character: simpsons_dataset, file: charles_montgomery_burns\n",
            "Error loading image, character: simpsons_dataset, file: chief_wiggum\n",
            "Error loading image, character: simpsons_dataset, file: cletus_spuckler\n",
            "Error loading image, character: simpsons_dataset, file: comic_book_guy\n",
            "Error loading image, character: simpsons_dataset, file: disco_stu\n",
            "Error loading image, character: simpsons_dataset, file: edna_krabappel\n",
            "Error loading image, character: simpsons_dataset, file: fat_tony\n",
            "Error loading image, character: simpsons_dataset, file: gil\n",
            "Error loading image, character: simpsons_dataset, file: groundskeeper_willie\n",
            "Error loading image, character: simpsons_dataset, file: homer_simpson\n",
            "Error loading image, character: simpsons_dataset, file: kent_brockman\n",
            "Error loading image, character: simpsons_dataset, file: krusty_the_clown\n",
            "Error loading image, character: simpsons_dataset, file: lenny_leonard\n",
            "Error loading image, character: simpsons_dataset, file: lionel_hutz\n",
            "Error loading image, character: simpsons_dataset, file: lisa_simpson\n",
            "Error loading image, character: simpsons_dataset, file: maggie_simpson\n",
            "Error loading image, character: simpsons_dataset, file: marge_simpson\n",
            "Error loading image, character: simpsons_dataset, file: martin_prince\n",
            "Error loading image, character: simpsons_dataset, file: mayor_quimby\n",
            "Error loading image, character: simpsons_dataset, file: milhouse_van_houten\n",
            "Error loading image, character: simpsons_dataset, file: miss_hoover\n",
            "Error loading image, character: simpsons_dataset, file: moe_szyslak\n",
            "Error loading image, character: simpsons_dataset, file: ned_flanders\n",
            "Error loading image, character: simpsons_dataset, file: nelson_muntz\n",
            "Error loading image, character: simpsons_dataset, file: otto_mann\n",
            "Error loading image, character: simpsons_dataset, file: patty_bouvier\n",
            "Error loading image, character: simpsons_dataset, file: principal_skinner\n",
            "Error loading image, character: simpsons_dataset, file: professor_john_frink\n",
            "Error loading image, character: simpsons_dataset, file: rainier_wolfcastle\n",
            "Error loading image, character: simpsons_dataset, file: ralph_wiggum\n",
            "Error loading image, character: simpsons_dataset, file: selma_bouvier\n",
            "Error loading image, character: simpsons_dataset, file: sideshow_bob\n",
            "Error loading image, character: simpsons_dataset, file: sideshow_mel\n",
            "Error loading image, character: simpsons_dataset, file: snake_jailbird\n",
            "Error loading image, character: simpsons_dataset, file: troy_mcclure\n",
            "Error loading image, character: simpsons_dataset, file: waylon_smithers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_-JMAeozXWV",
        "outputId": "d7253a81-ccff-4b8d-b98b-c2c559fa2e6c"
      },
      "id": "v_-JMAeozXWV",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20933, 112, 112, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8HuIr723v-O",
        "outputId": "00f40019-e465-4099-ec49-233ca5878860"
      },
      "id": "s8HuIr723v-O",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20933,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the numpy arrays \n",
        "# np.save('/content/drive/MyDrive/Detecting_Character/detecting_character_dataset/training_set_simpsons.npy', data)\n",
        "# np.save('/content/drive/MyDrive/Detecting_Character/detecting_character_dataset/labels_simpsons.npy', labels)\n",
        "     "
      ],
      "metadata": {
        "id": "IzP-msPb31-3"
      },
      "id": "IzP-msPb31-3",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r7h1RKub4WqZ"
      },
      "id": "r7h1RKub4WqZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}